% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Project Proposal CSCI 544: Attenuating Bias in Pre-trained Language Models using MABEL}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\author{Aditya Mantri Anulekh \\ {\bf Aditi Bodhankar} \\ {\bf Surya Teja CVN} \\ {\bf Nithyashree Manohar} \\ {\bf Advait Rane}}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Domain and Goals}
Pre-trained deep learning models encode harmful social biases which can have unintended consequences in downstream tasks. Language models inherit social biases when they are trained on text corpora that contain examples of such biases. Large Language Models have been to shown to encode biases along gender and religious lines. This has prompted recent research to explore ways to debias models and produce fair model outcomes. For our project, we aim to implement once such strategy, MABEL \cite{he2022mabel}, to reduce biases in pre-trained language models through a task-agnostic pre-training step.

MABEL describes an intermediate pre-training step to reduce gender bias in language representations. They use Natural Language Inference (NLI) as a pre-training task and augment the dataset to contain samples of the same sentence but with opposite genders. For example, if the sentence, "Woman putting together a wooden shelf" is present in the dataset, they add a new sentence, "Man putting together a wooden shelf". The paper restricts itself to the binary gender. 

The model is trained on the NLI task along with an alignment loss, to minimize the distance between original sentences and their augmented counterparts, and a contrastive loss, based on entailment of inference pairs. They then evaluate the model using intrinsic and extrinsic fairness metrics.

The goals for this project are-
\begin{enumerate}
    \item Implementing and evaluating MABEL, as described in the original paper.
    \item Evaluating the use of MABEL to reduce social biases along other dimensions, e.g., racial or religious
    \item Evaluating alternative strategies to debias model using the MABEL framework, e.g., by pre-training on a different task.
\end{enumerate}

\section{Related Work}

\section{Datasets}

We intend to follow the MABEL paper where the experiments are performed on two renowned NLI datasets, which are, Stanford Natural Language Inference (SNLI) \cite{SNLI_dataset_paper} and the Multi-Genre Natural Language Inference (MNLI) \cite{MNLI_dataset_paper}.
As a pre-processing step, we extract the sentence pairs with an entailment relationship. This basically is a hypothesis sentence that can be inferred to be true, based on a premise sentence. Since gender attribute is the prime focus, we extract all entailment pairs that contain at least one gendered term in either the premise or the hypothesis from an NLI dataset. For a sensitive attribute term in the sequence, swapping of a word is done along the opposite bias direction, that is, by changing "girl" to "boy" and the non-attribute words remain the same. This approach is followed for each sentence in every entailment pair.

\section{Technical Challenge}



\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\appendix

\end{document}
